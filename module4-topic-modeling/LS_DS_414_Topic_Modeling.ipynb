{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOMBkFKn6uEK"
   },
   "source": [
    "# Topic Modeling (Prepare)\n",
    "\n",
    "On Monday we talked about summarizing your documents using just token counts. Today, we're going to learn about a much more sophisticated approach - learning 'topics' from documents. Topics are a latent structure. They are not directly observable in the data, but we know they're there by reading them.\n",
    "\n",
    "> **latent**: existing but not yet developed or manifest; hidden or concealed.\n",
    "\n",
    "## Use Cases\n",
    "Primary use case: what the hell are your documents about? Who might want to know that in industry - \n",
    "* Identifying common themes in customer reviews\n",
    "* Discovering the needle in a haystack \n",
    "* Monitoring communications (Email - State Department) \n",
    "\n",
    "## Learning Objectives\n",
    "*At the end of the lesson you should be able to:*\n",
    "* Part 0: Warm-Up\n",
    "* Part 1: Describe how an LDA Model works\n",
    "* Part 2: Estimate a LDA Model with Gensim\n",
    "* Part 3: Interpret LDA results & Select the appropriate number of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxH0cRGX6uEL"
   },
   "source": [
    "# Part 0: Warm-Up\n",
    "How do we do a grid search? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnyNg8sQ6uEL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "boKWVkRz6uEO",
    "outputId": "2d3f688e-8cc8-44a4-9629-7c58285e1323"
   },
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and Y from data\n",
    "X = data.data\n",
    "Y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-39zg9a6uEQ"
   },
   "source": [
    "### GridSearch on Just Classifier\n",
    "* Fit the vectorizer and prepare BEFORE it goes into the gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "2q3NmHEo6uEQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5128f39ff0d1ae1703c1aab52256a9cc",
     "grade": false,
     "grade_id": "cell-510807d1dad0e53b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=-2,\n",
       "             param_grid={'max_depth': [None, 10], 'n_estimators': [10, 100]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tfidf instant\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# transform data\n",
    "X_dtm = tfidf.fit_transform(X)\n",
    "\n",
    "# create parameter dict\n",
    "param = {\n",
    "    \"n_estimators\": [10, 100], \n",
    "    \"max_depth\": [None, 10]\n",
    "}\n",
    "\n",
    "# create model instance \n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# instantiate a grid search object\n",
    "gs = GridSearchCV(rfc, \n",
    "                  param, \n",
    "                  cv = 3, \n",
    "                  n_jobs=-2, \n",
    "                  verbose=1)\n",
    "\n",
    "# optimize model parameters\n",
    "gs.fit(X_dtm, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gDkMaXvG83Zt",
    "outputId": "f3a55d86-209d-47b2-dd44-c23532ffcf2a"
   },
   "outputs": [],
   "source": [
    "# create and tranform a sample text \n",
    "sample_text = [\"I love baseball\"]\n",
    "\n",
    "# transform sample text outside of model\n",
    "sample_vect = tfidf.transform(sample_text)\n",
    "\n",
    "# use the model to classify the sample tet \n",
    "best_model = gs.best_estimator_\n",
    "\n",
    "# get prediction of sample text \n",
    "y_hat = best_model.predict(sample_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9]), 'rec.sport.baseball')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get prediction topic name\n",
    "y_hat, data.target_names[y_hat[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WdVTuXKl6uEZ"
   },
   "source": [
    "### GridSearch with BOTH the Vectoizer & Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "colab_type": "code",
    "deletable": false,
    "id": "97TjUtoI6uEZ",
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "000124c970341034e97d5534ae87d4c1",
     "grade": false,
     "grade_id": "cell-9f20cda21fe03f05",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "207e8cb3-5e82-4077-ac25-2406d21c3607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vect', TfidfVectorizer()),\n",
       "                                       ('clf', RandomForestClassifier())]),\n",
       "             n_jobs=-2,\n",
       "             param_grid={'clf__max_depth': [None, 7],\n",
       "                         'clf__n_estimators': [10, 20],\n",
       "                         'vect__max_features': [1000, 5000]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create tfidf instance\n",
    "v2 = TfidfVectorizer()\n",
    "\n",
    "# create model instance \n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Create a pipline instance using tfidf and your model \n",
    "pipe = Pipeline([\n",
    "    ('vect', v2),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "# create parameter dict\n",
    "p2 = {\n",
    "    'vect__max_features':[1000,5000],\n",
    "    'clf__n_estimators':[10,20],\n",
    "    'clf__max_depth': [None, 7]\n",
    "}\n",
    "\n",
    "# instantiate a grid search object\n",
    "gs2 = GridSearchCV(pipe, \n",
    "                   p2, \n",
    "                   cv=3,\n",
    "                   n_jobs=-2, \n",
    "                   verbose=1)\n",
    "\n",
    "# optimize model parameters\n",
    "gs2.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IdIE67Us6uEc"
   },
   "outputs": [],
   "source": [
    "# pass a raw text sample into the optimized model in order to classify it\n",
    "sample_text = [\"I love baseball\"]\n",
    "y_hat = gs2.predict(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2R2ACd36uEd"
   },
   "source": [
    "Advantages to using GS with the Pipe:\n",
    "* Allows us to make predictions on raw text increasing reproducibility. :)\n",
    "* Allows us to tune the parameters of the vectorizer along side the classifier. :D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbZjG6U86uEe"
   },
   "source": [
    "----\n",
    "# Part 1: Describe how an LDA Model works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your Guide to Latent Dirichlet Allocation](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d) Article that provides an explaination of LDA by using the same interactive tool that we use in class. \n",
    "\n",
    "[LDA Topic Modeling](https://lettier.com/projects/lda-topic-modeling/) Interactive tool that allows us to play with parameter values and see how that affects the output of applying LDA to a corpus. \n",
    "\n",
    "[Topic Modeling with Gensim](https://radimrehurek.com/gensim/) This is the documentation of the NLP library Gensim. Gensim has some pretty cool NLP specific ML modelings (such as LDA and doc2vec) that you can use. Definately a resource worth knowning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### About the video on LDA\n",
    "\n",
    "This video does a great job of using plently of visual aids and examples to accompany an **explaination of the underlying mathematics of LDA**. In other words, if you are interested in learning about the math of how LDA works, then definately check out this video. \n",
    "\n",
    "**Note:** Mathematical knowledge of LDA is considered optional. You will **not** be tested on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/T05t-SqKArY\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x124751940>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "# Check out this 4 minute video for a deeper discussion on LSA\n",
    "YouTubeVideo('T05t-SqKArY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yPIlE_IeF0cX",
    "outputId": "11cab929-9e79-43fd-fee7-08f42113cf24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# an alternative approach to downloading the spaCy pre-trained model \n",
    "\n",
    "# Download spacy model\n",
    "import spacy.cli\n",
    "# Note: please download and use the small version of spacy pre-trained model on the Sprint Challenge \n",
    "spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qapChu_UGBFc"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# our new NLP python package \n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "\n",
    "# pipenv install pyLDAvis\n",
    "# OR pip install pyLDAvis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "qaMsy1XAGLxc",
    "outputId": "0a981642-93ef-4a95-c6a2-c5ca7c5151e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenniferquigley/.local/share/virtualenvs/DS-Unit-4-Sprint-1-NLP-gQtURTt4/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'content': data['data'],\n",
    "    'target': data['target'],\n",
    "    'target_names': [data['target_names'][i] for i in data['target']]\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "qaMsy1XAGLxc",
    "outputId": "0a981642-93ef-4a95-c6a2-c5ca7c5151e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenniferquigley/.local/share/virtualenvs/DS-Unit-4-Sprint-1-NLP-gQtURTt4/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at an article\n",
    "# we can see that we need to do some data cleaning - let's create a function for that \n",
    "df.content.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "deletable": false,
    "id": "na2bkOcFGter",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e6d91ee81e6014b8aef75dda13f927f",
     "grade": false,
     "grade_id": "cell-6ce62b4e40acee5f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "6c8d1a19-3719-4e28-d8c6-d3202fdd6257"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenniferquigley/.local/share/virtualenvs/DS-Unit-4-Sprint-1-NLP-gQtURTt4/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\S\n",
      "<ipython-input-19-3fd3a149aa5a>:5: DeprecationWarning: invalid escape sequence \\S\n",
      "  doc = re.sub(\"From: \\S+@\\S+\", \"\", doc)\n"
     ]
    }
   ],
   "source": [
    "# can visit (https://regex101.com/) for a regex python editor (has cheat sheets!)\n",
    "def clean_data(doc):\n",
    "        \n",
    "    # Remove Emails\n",
    "    doc = re.sub(\"From: \\S+@\\S+\", \"\", doc)\n",
    "    \n",
    "    # Remove new line characters\n",
    "    doc = re.sub(\"\\n+\", \" \", doc)\n",
    "    \n",
    "    # Remove non-alphanumeric characters\n",
    "    doc = re.sub(\"[^0-9 a-zA-Z]+\", \"\", doc)\n",
    "    \n",
    "    doc = re.sub(\" +\", \" \", doc)\n",
    "    \n",
    "    # case normalization \n",
    "    doc = doc.lower()\n",
    "    \n",
    "    # Remove leading and trailing whitespace\n",
    "    return doc.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "deletable": false,
    "id": "na2bkOcFGter",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e6d91ee81e6014b8aef75dda13f927f",
     "grade": false,
     "grade_id": "cell-6ce62b4e40acee5f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "6c8d1a19-3719-4e28-d8c6-d3202fdd6257"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenniferquigley/.local/share/virtualenvs/DS-Unit-4-Sprint-1-NLP-gQtURTt4/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# this line of code iteraters throught the N number of docs \n",
    "# save clean data to a new feature for comparison with raw text \n",
    "df[\"clean_text\"] = df.content.apply(lambda doc: clean_data(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenniferquigley/.local/share/virtualenvs/DS-Unit-4-Sprint-1-NLP-gQtURTt4/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'wheres my thing subject what car is this nntppostinghost rac3wamumdedu organization university of maryland college park lines 15 i was wondering if anyone out there could enlighten me on this car i saw the other day it was a 2door sports car looked to be from the late 60s early 70s it was called a bricklin the doors were really small in addition the front bumper was separate from the rest of the body this is all i know if anyone can tellme a model name engine specs years of production where this car is made history or whatever info you have on this funky looking car please email thanks il brought to you by your neighborhood lerxst'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually inspect to see that you got your intended results \n",
    "df.clean_text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenniferquigley/.local/share/virtualenvs/DS-Unit-4-Sprint-1-NLP-gQtURTt4/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# (optional) this is how you download a python package inside of a notebook\n",
    "#!pip install pandarallel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 11 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenniferquigley/.local/share/virtualenvs/DS-Unit-4-Sprint-1-NLP-gQtURTt4/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "\n",
    "# find out how many processors your machine has N\n",
    "# then set nb_workers = N - 1\n",
    "n_cpus = 11\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=n_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenniferquigley/.local/share/virtualenvs/DS-Unit-4-Sprint-1-NLP-gQtURTt4/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# when working locally, feel free to use the large version of the pre-trained model\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EBPQXqEKE9P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenniferquigley/.local/share/virtualenvs/DS-Unit-4-Sprint-1-NLP-gQtURTt4/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c73f6444a834579b4346398fde7dd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1029), Label(value='0 / 1029'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# create our tokens in the form of lemmas \n",
    "# by using df.parallel_apply() we are using the parallel version of the apply method \n",
    "# should result in a shorter runtime \n",
    "df['lemmas'] = df['clean_text'].parallel_apply(lambda text: [token.lemma_ for token in nlp(text) if (token.is_stop != True) and (token.is_punct != True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The two main inputs to the LDA topic model are the dictionary (id2word) and the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the tokens/lemmas in a couple of formats that the LDA model is expecting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have over 11K docs \n",
    "# In class I took a subsample of 2000 docs so that the runtime would be much shorter \n",
    "# Debugging Pro tip! Take a subsample of data whenever 1) you have a big data set and 2) you're still testing your code and fixing bugs \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "1klqRpqtJxWc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd66ab4eff9f69a3e9be0aa57fdc2598",
     "grade": false,
     "grade_id": "cell-79d38b90e5c6e38b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "keep_N_docs = 2000\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(df[\"lemmas\"].iloc[:keep_N_docs])\n",
    "\n",
    "# Term Document Frequency for each doc -> doc-term matrix \n",
    "corpus = [id2word.doc2bow(list_of_token) for list_of_token in df[\"lemmas\"].iloc[:keep_N_docs]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# stores (token id, token count) for each doc in the corpus\n",
    "doc_id = 13\n",
    "corpus[doc_id]\n",
    "\n",
    "counter = 0\n",
    "# Human readable format of corpus (term-frequency)\n",
    "for token_id, token_count in corpus[doc_id]:\n",
    "    print (id2word[token_id], token_id)\n",
    "    \n",
    "    if counter == 10:\n",
    "        break  \n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Estimate a LDA Model with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Train an LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fasvjf0VLQ2a"
   },
   "outputs": [],
   "source": [
    "### This cell runs the single-processor version of the model (slower)\n",
    "# %%time\n",
    "\n",
    "# # USE THIS VERSION OF THE LDA MODEL DURING THE SPRINT CHALLENGE\n",
    "# lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "#                                            id2word=id2word,\n",
    "#                                            num_topics=20, \n",
    "#                                            chunksize=100,\n",
    "#                                            passes=10,\n",
    "#                                            per_word_topics=True)\n",
    "lda_model.save('lda_model.model')\n",
    "# # https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### This cell runs the multi-processor version of the model (faster)\n",
    "lda_multicore = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=20, \n",
    "                                                        chunksize=100,\n",
    "                                                        passes=3,\n",
    "                                                        per_word_topics=True,\n",
    "                                                        workers=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's a good idea to save models to memory that take a long time to train \n",
    "\n",
    "lda_multicore.save('lda_multicore.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how you load in trained models \n",
    "# see docs for more details: https://radimrehurek.com/gensim/models/ldamulticore.html\n",
    "\n",
    "from gensim import models\n",
    "lda_multicore =  models.LdaModel.load('lda_multicore.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Interpret LDA results & Select the appropriate number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYXi480VLaHK"
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_multicore, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is topic coherence?\n",
    "Topic Coherence measures score a single topic by **measuring the degree of semantic similarity between high scoring words in the topic**. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference.\n",
    "\n",
    "\n",
    "A set of statements or facts is said to be coherent, if they support each other. Thus, a coherent fact set can be interpreted in a context that covers all or most of the facts. An example of a coherent fact set is **“the game is a team sport”**, **“the game is played with a ball”**, **“the game demands great physical efforts”**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjtXk8J3LaXC"
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=num_topics, \n",
    "                                                        chunksize=100,\n",
    "                                                        passes=10,\n",
    "                                                        per_word_topics=True,\n",
    "                                                        workers=10)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=df['lemmas'].iloc[:keep_N_docs], start=2, limit=22, step=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use these values for the plot if compute_coherence_values takes too long to run \n",
    "#coherence_values = [0.5054, 0.5332, 0.5452, 0.564, 0.5678, 0.5518, 0.519]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=22; start=2; step=4;\n",
    "x = range(start, limit, step)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(x, coherence_values)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[1]\n",
    "#optimal_model =  models.LdaModel.load('optimal_model.model')\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "REFERENCE_LS_DS_414_Topic_Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
